# Параллельное программирование



## 1. Необходимость

​	Иногда выгоднее не придумывать алгоритм распараллеливания задачи, а просто купить больше вычислительной мощности. Например, зарплата среднего разработчика на языке C++ составляет около 150 тыс. руб. Если этому разработчику на переделывание системы понадобится больше месяца, мы будем в явном минусе - процессор помощнее стоит дешевле. 

​	Понятно, что иногда нам нужен прирост производительности, который невозможно обеспечить лишь за счет увеличения вычислительной мощности. В таких случаях затраты времени на проработку алгоритма параллельного программирования становятся оправданными.

​	Увеличив число ядер процессора в 10 раз, наивно ожидать прироста производительности в 10 раз. Хотя бы из-за затрат ОС на переключение между потоками. А еще у нас есть последовательный код, который невозможно распараллелить, например, ввод/вывод. Рассмотрим закон Амдала.

![dsf](https://latex.codecogs.com/gif.latex?S=\frac{1}{\alpha+\frac{1-\alpha}{p}}) *a* - доля последовательного кода,  *p* - число процессоров

​	Например, увеличив число процессоров в 10 раз и имея долю последовательного кода 0.2 получим S = 3,6. То есть прирост производительности меньше, чем в 4 раза.  



​	А может просто запустить несколько экземпляров программы на одном компьютере? Тогда и распараллеливать ничего не надо. Можно так сделать, но выгода будет гораздо меньше. Переключение потоков в рамках одного процесса для ОС намного дешевле и быстрее, чем переключение процессов. У ОС есть кэш процессов и при переключении между ними придется все время его обновлять, а при переключении потоков он не меняется.



## 2. Одно ядро

​	Предположим, в нашем процессоре только одно ядро. Можно ли в этом случае говорить о параллельном программировании? Да, поскольку все современные процессоры реализуют SSE (*Streaming SIMD Extensions*)

​	В SSE добавлены шестнадцать 128-битных регистров, которые называются xmm0 —xmm15. Над этими регистрами можно проводить различные математические операции одной процессорной инструкцией. 

​	Например, мы хотим перемножить 2 массива размера 4 поэлементно. В регистр xmm0 записываем весь первый массив, в регистр xmm1 второй массив. Одной инструкцией **mulps** получаем результат.

Более реалистичный пример. Требуется как можно быстрее найти сумму элементов массива `array[100_000]`. Рассмотрим несколько реализаций.

```c#
  public int Simple()
  {
      int sum = 0;
      foreach (var item in array)
      {
          sum += item;
      }
      return sum;
  }

  public int Linq()
  {
      return array.Sum();
  }

 public int Vector()
 {
     int vectorSize = Vector<int>.Count;
     var accVector = Vector<int>.Zero;
     int i;
     
     for (i = 0; i < array.Length - vectorSize; i += vectorSize)
     {
         var v = new Vector<int>(array, i);
         accVector = Vector.Add(accVector, v);
     }
     
     int result = Vector.Dot(accVector, Vector<int>.One);
     
     for (; i < array.Length; i++)
     {
         result += array[i];
     }
     return result;
 }
```

​	Если запустить тест у себя на компьютере, можно убедиться, что реализация через `Vector` работает быстрее.

​	 Платформа .NET предоставляет более низкое управление SSE инструкциями через пространство имен `System.Runtime.Intrinsics`. В нем находятся классы, позволяющие работать напрямую с аппаратным инструкциями разных типов процессоров.

 	Например, для Intel это класс `Avx2`. Классы `Sse`-`Sse4` предназначены для работы с разными версиями SSE. Все методы этих классов работают с структурой `Vector`, пользоваться ими приходится в редких случаях. 









## 3. Примитивы синхронизации



#### 	3.1.Mutex

​		Критическая секция для n потоков.

####     3.2. Рекурсивный Mutex

​		Рекурсивный означает, что вызов блокировки на уже заблокированном объекте не приводит в deadlock. То есть, можно в коде писать подряд

```c#
Lock(); 
Lock();
```

​		Когда это нужно? А вот, например.

```c#
public class Vector
{
    public void Push(int value)
    {
        Lock();
        if( Size() == 0)
        {
             // Выделить память
        }
        Unlock();
    }
    
    public int Size()
    {
        Lock();
        int countElements = 0;
        foreach( var item in items)
            countElements ++;
        Unlock();
        return countElements;
	}
}
```



#### 3.3.  Timed Mutex

​	Используется, когда нужно передавать в Lock максимальное время ожидания

#### 3.4. Shared Mutex

​	Рассмотрим последовательность  _wrrrrwwrrr_  доступа к разделяемому ресурсу, где *r*  - чтение, *w* - запись. Последовательности нескольких операция чтения можно объединять: `Lock(); Read();Read();Read(); Unlock()` 

#### 3.5. Spin Mutex

​	Планировщик потоков переводит поток в состояние ожидания, это довольно дорогая операция. Если ресурс захватывается ненадолго, можно активно ожидать, самостоятельно опрашивая, освободился ресурс или нет.

​	В C# оператор lock представляет собой:

```c#
private object x;
try
{
    Monitor.Enter(x);
}
finally
{
    Monitor.Exit(x);
}
```

Monitor это тот же Mutex, но работающий только в рамках одного процесса. ( так быстрее, потому что не впадаем в kernel space).



Дадим несколько определений. Операция называется **атомарной**, если она выполняется за 1 шаг для других потоков, то есть никто не может увидеть изменение в середине. Примером атомарной операции может служить запись в 



## 4. Алгоритмы синхронизации

Рассмотрим различные подходы к синхронизации на примере синхронизации доступа к односвязному списку.

#### 4.1. Грубая синхронизация

```c#
class MyList
{
    public void Add() // операция delete аналогично
    {
        Lock();
        // something
        Unlock();
	}
}
```

#### 4.2. Тонкая синхронизация (жертвуем памятью)

Чтобы произвести операцию удаления или добавления, достаточно блокирования только 2х соседних элементов. Поэтому, разные потоки могут одновременно менять что-то в нашем списке, если они на расстоянии больше 2х элементов.

#### 4.3. Оптимистичная синхронизация (грузим процессор)

1. Бежим вообще без блокировок

2. Нашли 2 элемента

3. Блокируем им. В этот момент что-то могло поменяться, например, они удалились.

4. Снова бежим до них. Если добежали, они существуют, делаем над ними операцию.

   

#### 4.4. Ленивая синхронизация

Помечаем элементы как удаленные, но реально не удаляем. Тогда поиск вообще без блокировок.

#### 4.5. Неблокирующая синхронизация

*CAS* - CompareAndSet, CompareAndSwap Это просто функция вида

```c#

```







## 5. Шаблоны || программирования







## 6. 